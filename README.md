
# çˆ¬å–ç™¾åº¦å›¾ç‰‡å„ç§ç‹—ç‹—çš„å›¾ç‰‡ï¼Œä½¿ç”¨caffeè®­ç»ƒæ¨¡å‹åˆ†ç±»

### tag:
______
python
selenium
PhantomJS
sklearn
BeautifulSoup
caffe

#### caffeçš„å®‰è£…ç­‰é…ç½®è¯·è‡ªè¡ŒæŸ¥é˜…ï¼Œå¯ä»¥å…ˆåªç¼–è¯‘ä¸€ä¸ªonly cpuçš„
#### gitä»£ç åœ°å€ï¼šhttps://github.com/bbfamily/DogJudge
#### å¦‚æœ‰ä»»ä½•é—®é¢˜åŠ å¾®ä¿¡è”ç³» å¾®ä¿¡å·ï¼š**aaaabbbuu**

## 1. ä»£ç†è·å–

çˆ¬ä¸€äº›æä¾›å…è´¹ä»£ç†çš„ç½‘ç«™ï¼Œè·å–åˆ°çš„ä»£ç†è¦æ ¹æ®é€Ÿåº¦è¦æ±‚ç­‰checkï¼Œ
å¯æ‰©å±•çˆ¬å–çš„ç½‘ç«™ï¼Œè¿™é‡Œåªç®€å•çˆ¬äº†ä¸¤ä¸ªï¼Œä»£ç†è´¨é‡ä¸€èˆ¬ï¼Œä¹Ÿå¯ä»¥ç”¨
Torä¸è¿‡å¥½åƒä¹Ÿä¸æ€ä¹ˆå¥½ä½¿äº†

    from SpiderProxy import SpiderProxy
    import ZLog
    ZLog.init_logging()

    pxy = SpiderProxy()
    pxy.spider_proxy360()
    pxy.spider_xicidaili()
    pxy.check_proxy()
    pxy.save_csv()
    
    output:
    211.151.48.60:8080 check ok
    139.196.108.68:80 check ok
    110.178.198.55:8888 check ok
    106.75.128.90:80 check ok
    60.194.100.51:80 check ok
    117.57.188.176:81 check ok
    45.32.19.10:3128 check ok
    110.181.181.164:8888 check ok
    39.87.237.90:81 check ok
    111.206.81.248:80 check ok
    47.89.53.92:3128 check ok
    112.87.106.217:81 check ok
    218.89.69.211:8088 check ok
    139.59.180.41:8080 check ok
    124.133.230.254:80 check ok
    128.199.186.153:8080 check ok
    192.249.72.148:3128 check ok
    112.112.70.116:80 check ok
    128.199.178.73:8080 check ok
    178.32.153.219:80 check ok
    79.141.70.78:3128 check ok
    119.6.136.122:80 check ok
    46.219.78.221:8081 check ok
    proxy_list len=23

## 2. ç‹—ç‹—åˆ†ç±»æ•°æ®è·å–

çˆ¬è™«å¯è®¾ç½®é¡¹ï¼š

* g_enable_show:æ˜¯å¦ä½¿ç”¨æœ‰ç•Œé¢æµè§ˆå™¨è¿˜æ˜¯ä½¿ç”¨PHANTOMJS

* g_enable_proxy:æµè§ˆå™¨çš„è¿›ç¨‹æ˜¯å¦å¯ç”¨ä»£ç†ï¼Œé»˜è®¤ä¸éœ€è¦ï¼Œä¸‹è½½åŸå›¾ä¸€å®šæ˜¯ä½¿ç”¨ä»£ç†æ²¡æœ‰å¼€å…³

* g_enable_debug:å•è¿›ç¨‹ï¼Œå•çº¿ç¨‹è°ƒè¯•æ¨¡å¼å¯ä»¥debugæ–­ç‚¹

* g_enable_streamä½¿ç”¨æµä¸‹è½½å›¾ç‰‡

* K_SCROLL_MOVE_DISTANCE = 200 æ¨¡æ‹Ÿjs windowä¸‹æ»‘è·ç¦»ï¼Œå¢å¤§æé«˜çˆ¬å–é€Ÿåº¦

* K_SCROLL_SLEEP_TIME = 3 

* K_COLLECT_PROCESS_CNT = 3 åŒæ—¶å¯åŠ¨è¿›ç¨‹ä¸ªæ•°

ç”±äºä½¿ç”¨äº†çº¿ç¨‹æ± æ§åˆ¶maxçº¿ç¨‹æ•°ï¼Œæ‰€ä»¥å°±ç®—ä½ æé«˜K_SCROLL_MOVE_DISTANCEï¼ŒK_SCROLL_SLEEP_TIMEä¹Ÿä¸ä¼šæœ‰ä¸‹è½½é€Ÿåº¦çš„æå‡ï¼Œ
éœ€è¦ä¿®æ”¹çº¿ç¨‹æ± åˆå§‹åŒ–ç°åœ¨è®¾ç½®äº†3å€ä»£ç†æ•°é‡ï¼Œå…·ä½“è¯¦çœ‹ä»£ç ï¼š
    with ThreadPoolExecutor(max_workers=len(self.back_proxys) * 3) as executor:


**é»˜è®¤å¯åŠ¨googleæœ‰ç•Œé¢æµè§ˆå™¨äº†ï¼Œå› ä¸ºä»£ç†è´¨é‡å¤ªå·®ï¼Œæ‰€ä»¥å°±èµ·äº†ä¸‰ä¸ªè¿›ç¨‹ï¼Œå¦‚æœè¦å¯åŠ¨å¤šä¸ªè¿›ç¨‹åœ¨ä¹æ•ˆç‡ï¼Œä»£ç†è´¨é‡å¤Ÿå¥½ï¼Œè¦ä½¿ç”¨PHANTOMJS**

    n_jobs = 3
    if g_enable_debug:
        n_jobs = 1
    parallel = Parallel(
        n_jobs=n_jobs, verbose=0, pre_dispatch='2*n_jobs')

    parallel(delayed(do_spider_parallel)(proxy_df, ind, search_name) for ind, search_name in enumerate(search_list))
    
**ä½¿ç”¨seleniumé…åˆBeautifulSoupï¼Œrequestsçˆ¬å–å›¾ç‰‡ï¼Œè¾¾åˆ°ç›®æ ‡æ•°é‡æˆ–è€…åˆ°æ‰€æœ‰å›¾ç‰‡åœæ­¢
å…·ä½“è¯·å‚è€ƒSpiderBdImg**

    SpiderBdImg.spider_bd_img([u'æ‹‰å¸ƒæ‹‰å¤š', u'å“ˆå£«å¥‡', u'é‡‘æ¯›', u'è¨æ‘©è€¶', u'æŸ¯åŸº', u'æŸ´çŠ¬',
                                u'è¾¹å¢ƒç‰§ç¾ŠçŠ¬', u'æ¯”æ ¼', u'å¾·å›½ç‰§ç¾ŠçŠ¬', u'æœå®¾', u'æ³°è¿ªçŠ¬', u'åšç¾', u'å·´å“¥', u'ç‰›å¤´æ¢—'],
                                use_cache=True)
                                
    output:
    makedirs ../gen/baidu/image/é‡‘æ¯›
    makedirs ../gen/baidu/image/å“ˆå£«å¥‡
    makedirs ../gen/baidu/image/æ‹‰å¸ƒæ‹‰å¤š
    makedirs ../gen/baidu/image/è¨æ‘©è€¶
    makedirs ../gen/baidu/image/æŸ¯åŸº
    makedirs ../gen/baidu/image/æŸ´çŠ¬
    makedirs ../gen/baidu/image/è¾¹å¢ƒç‰§ç¾ŠçŠ¬
    makedirs ../gen/baidu/image/æ¯”æ ¼
    makedirs ../gen/baidu/image/å¾·å›½ç‰§ç¾ŠçŠ¬
    makedirs ../gen/baidu/image/æœå®¾
    makedirs ../gen/baidu/image/æ³°è¿ªçŠ¬
    makedirs ../gen/baidu/image/åšç¾
    makedirs ../gen/baidu/image/å·´å“¥
    makedirs ../gen/baidu/image/ç‰›å¤´æ¢—

## 3. ä¸‹ä¸€æ­¥ï¼Œäººå·¥å¤§æ¦‚æ‰«ä¸€ä¸‹å›¾ç‰‡ï¼ŒæŠŠå¤ªè¿‡ä»½çš„åˆ äº†ï¼Œä¸ç”¨å¤ªä»”ç»†ï¼Œå¤ªæ¦‚æ‰«æ‰«å°±å®Œäº‹,  è¿™å·¥å…·å…¶å®ä¹Ÿæ˜¯å¯ä»¥è‡ªåŠ¨è¯†åˆ«çš„ï¼Œå…ˆè‡ªå·±æ‰«æ‰«å§

![image](./Snip20160930_2.png)

![image](./Snip20160930_5.png)

## 4. æ•°æ®æ ‡å‡†åŒ–
        
        ä¸ºcaffeçš„lmdbåšå‡†å¤‡å°†å›¾ç‰‡éƒ½è½¬æ¢æˆjpegï¼Œå› ä¸ºä½œlmdbä½¿ç”¨opencvå…¶å®ƒæ ¼å¼æœ‰é—®é¢˜
        åŒ…æ‹¬ä¸‹è½½ä¸‹æ¥çš„gifï¼Œpngç­‰ç­‰æ‰¾åˆ°å›¾ç‰‡ï¼Œè¾¨è¯†çœŸå®å›¾ç‰‡ç±»å‹ï¼Œå‘½åçœŸå®åç§°åç¼€ï¼Œå°†éjpegçš„è½¬åŒ–ä¸ºjpeg
        å…·ä½“å‚è€ƒImgStdHelper
        
è¿è¡ŒæˆåŠŸåæ‰€æœ‰å›¾ç‰‡ä¸ºjpegåç¼€åç§°

    import ImgStdHelper
    ImgStdHelper.std_img_from_root_dir('../gen/baidu/image/', 'jpg')

## 5. å¼€å§‹è®­ç»ƒæ¨¡å‹åŠå‡†å¤‡

#### 5.1  ç”Ÿæˆè®­ç»ƒé›†æ–‡ä»¶

    !../sh/DogType.sh
    
            output:
            mkdir: ../gen/dog_judge: File exists
            Create train.txt...
            train.txt Done..

ç”Ÿæˆå¦‚ä¸‹æ ¼å¼æ•°æ®ï¼Œå…·ä½“å‚çœ‹gen/dog_judge/Train.txt

    train_path = '../gen/dog_judge/Train.txt'
    print open(train_path).read(400)
            
            output:
            å“ˆå£«å¥‡/001e5dd0f5aa0959503324336f24a5ea.jpeg 1
            å“ˆå£«å¥‡/001eae03d6f282d1e9f4cb52331d3e20.jpeg 1
            å“ˆå£«å¥‡/0047ea48c765323a53a614d0ed93353b.jpeg 1
            å“ˆå£«å¥‡/006e3bd75b2375149dab9d0323b9fc59.jpeg 1
            å“ˆå£«å¥‡/0084e12ec1c15235a78489a0f4703859.jpeg 1
            å“ˆå£«å¥‡/009724727e40158f5b84a50a7aaaa99b.jpeg 1
            å“ˆå£«å¥‡/00a9d66c72bbed2861f632d07a98db8d.jpeg 1
            å“ˆå£«å¥‡/00dabcba4437f77859b1d8ed37c85360.jpeg 1

ç”Ÿæˆæ•°å­—ç±»åˆ«å¯¹åº”çš„labelæ–‡ä»¶

    import pandas as pd
    class_map = pd.DataFrame(np.array([[1, 2, 3, 4, 5, 6], ['å“ˆå£«å¥‡', 'æ‹‰å¸ƒæ‹‰å¤š', 'åšç¾', 'æŸ´çŠ¬', 'å¾·å›½ç‰§ç¾ŠçŠ¬', 'æœå®¾']]).T, 
                            columns=['class', 'name'], 
                            index=np.arange(0, 6))
    class_map.to_csv('../gen/class_map.csv', columns=class_map.columns, index=True)

#### 5.2 ç”Ÿæˆvalï¼Œtesté›† 

**TrainValSplit å°†trainçš„æ•°æ®é›†æ¯ä¸ªç±»åˆ«æŒ‰ç…§n_folds=10å³åˆ†æˆååˆ†ï¼Œvalå ä¸€åˆ†ï¼Œtrainå ä¹ä»½ï¼Œä¸scikitç­‰åˆ†å‰²å‚æ•°n_foldsç”¨æ³•ä¸€æ ·
åœ¨genä¸‹é‡æ–°ç”Ÿæˆè®­ç»ƒæ•°æ®é›†ï¼Œæµ‹è¯•æ•°æ®é›†ï¼Œäº¤ç»‡æµ‹è¯•æ•°æ®é›†ï¼Œè¿™é‡Œçš„testä¸valæ•°æ®ä¸€æ ·ä¸è¿‡ï¼Œtestæ²¡æœ‰åˆ†ç±»æ ‡æ³¨**

    def train_val_split(train_path, n_folds=10):
        if n_folds <= 1:
            raise ValueError('n_folds must > 1')

        with open(train_path, 'r') as f:
            lines = f.readlines()
            class_dict = defaultdict(list)
            for line in lines:
                cs = line[line.rfind(' '):]
                class_dict[cs].append(line)

        train = list()
        val = list()
        for cs in class_dict:
            cs_len = len(class_dict[cs])
            val_cnt = int(cs_len / n_folds)
            val.append(class_dict[cs][:val_cnt])
            train.append(class_dict[cs][val_cnt:])
        val = list(itertools.chain.from_iterable(val))
        train = list(itertools.chain.from_iterable(train))
        test = [t.split(' ')[0] for t in val]

        fn = os.path.dirname(train_path) + '/train_split.txt'
        with open(fn, 'w') as f:
            f.writelines(train)
        fn = os.path.dirname(train_path) + '/val_split.txt'
        with open(fn, 'w') as f:
            f.writelines(val)
        fn = os.path.dirname(train_path) + '/test_split.txt'
        with open(fn, 'w') as f:
            f.writelines(test)

    import TrainValSplit
    TrainValSplit.train_val_split(train_path, n_folds=10)
    train_path = '../gen/dog_judge/train_split.txt'
    with open(train_path) as f:
        print 'train set len = {}'.format(len(f.readlines()))
    val_path = '../gen/dog_judge/val_split.txt'
    with open(val_path) as f:
        print 'val set len = {}'.format(len(f.readlines()))
        
        
        output:
        train set len = 9628
        val set len = 1066

#### 5.2 ç”Ÿæˆå›¾ç‰‡lmdbæ•°æ®åº“

        echo "Begin..."

        ROOTFOLDER=../gen/baidu/image
        OUTPUT=../gen/dog_judge

        rm -rf $OUTPUT/img_train_lmdb
        /Users/Bailey/caffe/build/tools/convert_imageset --shuffle \
        --resize_height=256 --resize_width=256 \
        $ROOTFOLDER $OUTPUT/train_split.txt  $OUTPUT/img_train_lmdb

        rm -rf $OUTPUT/img_val_lmdb
        /Users/Bailey/caffe/build/tools/convert_imageset --shuffle \
        --resize_height=256 --resize_width=256 \
        $ROOTFOLDER $OUTPUT/val_split.txt  $OUTPUT/img_val_lmdb

        echo "Done.."

    !../sh/DogLmdb.sh

æœ‰äº›æ˜¾ç¤ºCould not open or find fileçš„æ˜¯å¦‚ä¸‹è¿™å¼ ä¸‹è½½å°±ä¸‹è½½æ®‹äº†çš„ï¼Œæœ¬æ¥å°±éœ€è¦å¹²æ‰


```python
PIL.Image.open('../gen/baidu/image/å¾·å›½ç‰§ç¾ŠçŠ¬/023ee4e18ebfa4a3db8793e275fae47e.jpeg')
```




![png](./readme/output_25_0.png)



#### 5.4 ç”Ÿæˆå»å‡å€¼mean pbæ–‡ä»¶
       
**æ³¨æ„éœ€è¦æ›¿æ¢DogMean.shä¸­caffeçš„è·¯å¾„æ–‡ä»¶ä¸ºä½ çš„ç›®å½•æ–‡ä»¶MEANBIN=/Users/Bailey/caffe/build/tools/compute_image_mean**

    !../sh/DogMean.sh
    
        oytput:
        Begin...
        ../gen/dog_judge/mean.binaryproto
        ../gen/dog_judge/mean_val.binaryproto
        Done..

#### 5.5 ä½¿ç”¨bvlc_googlenetçš„solver.prototxtï¼Œtrain_val.prototxtè®­ç»ƒè‡ªå·±çš„æ•°æ®

_____


**
æ ¹æ®è®­ç»ƒæ•°æ®åŠæµ‹è¯•æ•°æ®çš„é‡ä¿®æ”¹solver.prototxtï¼Œtrain_val.prototxt**

**ç”±äºæµ‹è¯•æ•°æ®å¤§æ¦‚1000 ï¼> batch_size=50, test_iter: 20**

**è®­ç»ƒæ•°æ®å¤§æ¦‚10000 ï¼> test_interval: 1000**

**display: 100 snapshot: 5000(å…¶å®snapshotå¤§ç‚¹æ²¡äº‹ï¼Œåæ­£æ²¡æ¬¡crl ï¼‹ cç»“æŸæ—¶ä¼šç”Ÿæˆmode), å¦‚è¿‡éœ€è¦å¤šç•™å‡ ä¸ªåšå¯¹æ¯”ï¼Œå¯è°ƒå°**

**å¯ä»¥æŠŠtestçš„mirrorè®¾ç½®trueåæ­£æ•°æ®ä¸ç®—å¤š**

**ä¿®æ”¹DogTrain.sh ä¸­CAFEBIN=/Users/Bailey/caffe/build/tools/caffeä¸ºä½ çš„caffeè·¯å¾„**

**ä¿®æ”¹solver.prototxtï¼Œtrain_val.prototxtä¸­æ‰€æœ‰ç»å¯¹è·¯å¾„ä¸ºä½ çš„è·¯å¾„ï¼Œæ²¡æ³•ä½¿ç”¨ç›¸å¯¹è·¯å¾„é™¤éæƒ³å¯¹caffeè·¯å¾„ï¼Œé‚£æ ·æ›´éº»çƒ¦**

### è¯¦æƒ…è¯·å‚è€ƒsolver.prototxtï¼Œtrain_val.prototxt

ä¹‹åä½¿ç”¨!../sh/DogTrain.shå¼€å§‹è®­ç»ƒæ•°æ®ï¼Œç”±äºè¦æ‰“å¤ªå¤šæ—¥å¿—ï¼Œå°±ä¸åœ¨ipythonä¸­è¿è¡Œäº†ï¼Œå•ç‹¬å¯ä¸ªçª—å£æ¥, ç”Ÿæˆcaffemodel

## 6. ä½¿ç”¨ç”Ÿæˆçš„æ¨¡å‹è¿›è¡Œåˆ†ç±»

    6.1 æ„é€ caffe net

    import caffe
    caffe.set_mode_cpu()

    model_def = '../pb/deploy.prototxt'
    model_weights = '../gen/dog_judge/dog_judge_train_iter_5000.caffemodel'
    model_mean_file = '../gen/dog_judge/mean.binaryproto'

    net = caffe.Net(model_def, model_weights, caffe.TEST)  
    mean_blob = caffe.proto.caffe_pb2.BlobProto()
    mean_blob.ParseFromString(open(model_mean_file, 'rb').read())
    mean_npy = caffe.io.blobproto_to_array(mean_blob)
    mu = mean_npy.mean(2).mean(2)[0]
    print 'mu = {}'.format(mu)
    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})
    transformer.set_transpose('data', (2,0,1))  
    transformer.set_mean('data', mu)           
    transformer.set_raw_scale('data', 255)     
    transformer.set_channel_swap('data', (2,1,0))  

    for layer_name, blob in net.blobs.iteritems():
        print layer_name + '\t' + str(blob.data.shape)

    import numpy as np
    import matplotlib.pyplot as plt
    import glob
    %matplotlib inline

    plt.rcParams['figure.figsize'] = (10, 10)   

**ä¸»è§’ğŸ¶ç»ˆäºè¦ä¸Šåœºäº†æˆ‘å®¶æ‹‰å¸ƒæ‹‰å¤šé˜¿å¸ƒï¼Œä½¿ç”¨é˜¿å¸ƒçš„å¹³æ—¶ç”Ÿæ´»ç…§ç‰‡ä½œä¸ºæµ‹è¯•çœ‹çœ‹å‡†ç¡®ç‡æ€ä¹ˆæ ·**

    class_map = pd.read_csv('../gen/class_map.csv', index_col=0)


```python
class_map
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>class</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>å“ˆå£«å¥‡</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>æ‹‰å¸ƒæ‹‰å¤š</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>åšç¾</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>æŸ´çŠ¬</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>å¾·å›½ç‰§ç¾ŠçŠ¬</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>æœå®¾</td>
    </tr>
  </tbody>
</table>
</div>



    predict_dir = '../abu' 
    img_list = glob.glob(predict_dir + '/*.jpeg')
    len(img_list)
        
        output:
        22

    error_prob = []
    for img in img_list:
        image = caffe.io.load_image(img)
        transformed_image = transformer.preprocess('data', image)
        plt.imshow(image)
        plt.show()
        net.blobs['data'].data[...] = transformed_image
        output = net.forward()
        output_prob = output['prob'][0]
        print 'predicted class is:', class_map[class_map['class'] == output_prob.argmax()].name.values[0]
        if output_prob.argmax() <> 2:
            error_prob.append(img)


```python
print 'predicted class is:', class_map[class_map['class'] == output_prob.argmax()].name.values[0]
```


![png](./readme/output_40_0.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_2.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_4.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_6.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_8.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_10.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_12.png)


    predicted class is: å¾·å›½ç‰§ç¾ŠçŠ¬



![png](./readme/output_40_14.png)


    predicted class is: åšç¾



![png](./readme/output_40_16.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_18.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_20.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_22.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_24.png)


    predicted class is: æœå®¾



![png](./readme/output_40_26.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_28.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_30.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_32.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_34.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_36.png)


    predicted class is: æœå®¾



![png](./readme/output_40_38.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_40.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š



![png](./readme/output_40_42.png)


    predicted class is: æ‹‰å¸ƒæ‹‰å¤š


èƒ½åˆ°80%çš„æŸ¥å‡†ç‡å…¶å®å‡ºä¹æˆ‘é¢„æ–™ï¼Œåœ¨æ•°æ®ä¸ç®—å¤šï¼Œä¸”è´¨é‡ä¸€èˆ¬çš„æƒ…å†µä¸‹èƒ½è¾¾åˆ°è¿™ç§æ•ˆæœä¸å¾—ä¸è¯´caffeç¡®å®ç‰›
æœ‰äº›ç…§ç‰‡æ¯”å¦‚é˜¿å¸ƒæ‹‰å±é‚£ä¸ªï¼Œèººç€ç¡è§‰è€³æœµéƒ½ç«‹èµ·æ¥é‚£ä¸ªéƒ½åˆ¤æ–­å¯¹äº†ï¼Œæˆ‘è¿˜ä»¥ä¸ºå¾—åˆ¤æ–­æˆå“ˆå£«å¥‡å‘¢

    accuary = (len(img_list) - len(error_prob))/float(len(img_list))
    accuary
    
        output:
        0.8181818181818182

çœ‹ä¸€éåˆ†é”™çš„è¿™å‡ ä¸ªï¼Œæ„Ÿè§‰é”™çš„rankåŸºæœ¬ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«æŒ–æ˜çš„

    for img in error_prob:
        try:
            image = caffe.io.load_image(img)
        except Exception:
            continue
        transformed_image = transformer.preprocess('data', image)
        plt.imshow(image)
        plt.show()
        net.blobs['data'].data[...] = transformed_image
        output = net.forward()
        output_prob = output['prob'][0]
        top_inds = output_prob.argsort()[::-1][:6] 
        for rank, ind in enumerate(top_inds, 1):
            print 'probabilities rank {} label is {}'.format(rank, class_map[class_map['class']==ind].name.values[0])


```python
print 'probabilities rank {} label is {}'.format(rank, class_map[class_map['class']==ind].name.values[0])
```


![png](./readme/output_45_0.png)


    probabilities rank 1 label is å¾·å›½ç‰§ç¾ŠçŠ¬
    probabilities rank 2 label is æœå®¾
    probabilities rank 3 label is æ‹‰å¸ƒæ‹‰å¤š
    probabilities rank 4 label is æŸ´çŠ¬
    probabilities rank 5 label is åšç¾
    probabilities rank 6 label is å“ˆå£«å¥‡



![png](./readme/output_45_2.png)


    probabilities rank 1 label is åšç¾
    probabilities rank 2 label is æŸ´çŠ¬
    probabilities rank 3 label is æ‹‰å¸ƒæ‹‰å¤š
    probabilities rank 4 label is å“ˆå£«å¥‡
    probabilities rank 5 label is æœå®¾
    probabilities rank 6 label is å¾·å›½ç‰§ç¾ŠçŠ¬



![png](./readme/output_45_4.png)


    probabilities rank 1 label is æœå®¾
    probabilities rank 2 label is å¾·å›½ç‰§ç¾ŠçŠ¬
    probabilities rank 3 label is æŸ´çŠ¬
    probabilities rank 4 label is å“ˆå£«å¥‡
    probabilities rank 5 label is æ‹‰å¸ƒæ‹‰å¤š
    probabilities rank 6 label is åšç¾



![png](./readme/output_45_6.png)


    probabilities rank 1 label is æœå®¾
    probabilities rank 2 label is æ‹‰å¸ƒæ‹‰å¤š
    probabilities rank 3 label is å¾·å›½ç‰§ç¾ŠçŠ¬
    probabilities rank 4 label is æŸ´çŠ¬
    probabilities rank 5 label is åšç¾
    probabilities rank 6 label is å“ˆå£«å¥‡


å°±å†™åˆ°è¿™é‡Œå§ï¼Œè¿˜æ‹¿é˜¿å¸ƒç©çš„ç…§ç‰‡åˆ†äº†ä¸¤ç±»ä¸€ç±»æ˜¯åœ¨è‰åœ°ç©ï¼Œ ä¸€ç±»æ˜¯åœ¨æ°´é‡Œç©ï¼Œè®­ç»ƒäº†æ¨¡å‹åæµ‹è¯•å‘ç°å‡†ç¡®ç‡
ä¹Ÿç›¸å½“é«˜ï¼Œè¯´æ˜**é’ˆå¯¹å°æ•°æ®é›†ï¼Œcaffeç¡®å®ä¹Ÿå¯ä»¥å·¥ä½œçš„ä¸é”™**

## æ„Ÿè°¢ğŸ™æ‚¨èƒ½æœ‰è€å¿ƒçœ‹åˆ°è¿™é‡Œ
## å¦‚æœæœ‰ä»€ä¹ˆé—®é¢˜å¯ä»¥åŠ é˜¿å¸ƒçš„å¾®ä¿¡ 
## å¾®ä¿¡å·ï¼šaaaabbbuu

![image](./mmexport1475383814280.jpg)


```python

```
